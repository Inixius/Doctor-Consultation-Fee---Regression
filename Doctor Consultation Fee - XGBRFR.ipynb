{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7c7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98402f0",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d259c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"train.xlsx\")\n",
    "train.drop_duplicates(inplace = True)\n",
    "train[\"Experience\"] = train.Experience.apply(lambda x : ''.join(x.split(' ')[:1]))\n",
    "train['Experience'] = pd.to_numeric(train['Experience'])\n",
    "train[\"Rating\"] = train.Rating.apply(lambda x: ''.join(str(x).split('%')[:1]) if pd.notnull(x) else x)\n",
    "train['Rating'] = pd.to_numeric(train['Rating'], errors = 'coerce')\n",
    "train['Rating'] = train['Rating'].fillna(0)\n",
    "train['Rating'] = train['Rating'].astype('int64')\n",
    "train['Place'].fillna('missing', inplace=True)\n",
    "train[\"Area\"] = train.Place.apply(lambda x: ''.join(str(x).split(',')[:1]) if pd.notnull(x) else x)\n",
    "train[\"City\"] = train.Place.apply(lambda x: ''.join(str(x).split(',')[1:]) if pd.notnull(x) else x)\n",
    "train[\"City\"] = train.City.apply(lambda x: ''.join(str(x).split(' ')[1:]) if pd.notnull(x) else x)\n",
    "train['Miscellaneous_Info'].fillna('missing', inplace = True)\n",
    "train[\"Feedbacks\"] = train.Miscellaneous_Info.apply(lambda x: ''.join(str(x).split('%')[1:]) if pd.notnull(x) else x)\n",
    "train[\"Feedbacks\"] = train.Feedbacks.apply(lambda x: ''.join(str(x).split('F')[:1]) if pd.notnull(x) else x)\n",
    "train[\"Feedbacks\"] = train.Feedbacks.apply(lambda x: ''.join(str(x).split(' ')[1:]) if pd.notnull(x) else x)\n",
    "train.loc[train['Feedbacks'] == '', 'Feedbacks'] = '0'\n",
    "train['Feedbacks'] = pd.to_numeric(train['Feedbacks'], errors = 'coerce')\n",
    "train['Feedbacks'].fillna(0, inplace = True)\n",
    "train['Feedbacks'] = train['Feedbacks'].astype('int64')\n",
    "train[\"Misc_Fees\"] = train.Miscellaneous_Info.apply(lambda x: ''.join(str(x).split('₹')[1:]) if pd.notnull(x) else x)\n",
    "train['Misc_Fees'] = train['Misc_Fees'].str.replace(',', '')\n",
    "train[\"Misc_Fees\"] = train.Misc_Fees.apply(lambda x: ''.join(str(x).split(' ')[:1]) if pd.notnull(x) else x)\n",
    "train.loc[train['Misc_Fees'] == '', 'Misc_Fees'] = '0'\n",
    "train['Misc_Fees'] = pd.to_numeric(train['Misc_Fees'], errors = 'coerce')\n",
    "train['Misc_Fees'].fillna(0, inplace = True)\n",
    "train['Misc_Fees'] = train['Misc_Fees'].astype('int64')\n",
    "train.drop_duplicates(inplace = True)\n",
    "train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebaa6fb",
   "metadata": {},
   "source": [
    "## WINSORIZING OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86dc25c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# plt.rcParams['figure.figsize'] = (15,7)\n",
    "# f,(ax1, ax2) = plt.subplots(1,2)\n",
    "# sns.boxplot(y = 'Experience', data = train, ax = ax1, palette = 'coolwarm')\n",
    "# sns.boxplot(y = 'Rating', data = train, ax = ax2)\n",
    "# f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455360d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in ['Experience', 'Rating']:\n",
    "#     IQR = train[column].quantile(0.75) - train[column].quantile(0.25)\n",
    "#     Lower_fence = train[column].quantile(0.25) - (IQR * 1.5)\n",
    "#     Upper_fence = train[column].quantile(0.75) + (IQR * 1.5)\n",
    "#     print(f'{column} outliers are values < {round(Lower_fence,2)} or > {round(Upper_fence,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f05f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Experience'] = np.where(train['Experience'] > 44.0, 44.0, train['Experience'])\n",
    "# train['Rating'] = np.where(train['Rating'] < 91.0, 91.0, train['Rating'])\n",
    "# train['Rating'] = np.where(train['Rating'] > 99.0, 99.0, train['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609facd",
   "metadata": {},
   "source": [
    "## DUMMIFICATION, MIN-MAX SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97eee5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.get_dummies(train[['Profile', 'City']], drop_first = True)\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# scaled1 = scaler.fit_transform(train[['Experience', 'Rating']])\n",
    "# scaled1 = pd.DataFrame(scaled1, columns = ['Experience', 'Rating'])\n",
    "\n",
    "X1 = pd.concat([train[['Experience', 'Rating', 'Misc_Fees', 'Feedbacks']], X1], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e6e68",
   "metadata": {},
   "source": [
    "## XGB RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac99e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result: 0.7260061827421758\n",
      "Test Result: 0.7268551032763886\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, train['Fees'], test_size = 0.3, random_state = 1234)\n",
    "\n",
    "from xgboost import XGBRFRegressor\n",
    "model = XGBRFRegressor(random_state = 1234)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "result_train = 1 - np.sqrt(np.square(np.log10(y_pred_train +1) - np.log10(y_train +1)).mean())\n",
    "y_pred_test = model.predict(X_test)\n",
    "result_test = 1 - np.sqrt(np.square(np.log10(y_pred_test +1) - np.log10(y_test +1)).mean())\n",
    "print(\"Train Result:\", result_train)\n",
    "print(\"Test Result:\", result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a828d",
   "metadata": {},
   "source": [
    "## RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49868a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of features: 16\n",
      "Best features: Index(['Experience', 'Rating', 'Misc_Fees', 'Feedbacks', 'Profile_Dentist',\n",
      "       'Profile_Dermatologists', 'Profile_ENT Specialist',\n",
      "       'Profile_General Medicine', 'Profile_Homeopath', 'City_Bangalore',\n",
      "       'City_Chennai', 'City_Coimbatore', 'City_Delhi', 'City_Ernakulam',\n",
      "       'City_Mumbai', 'City_Thiruvananthapuram'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfecv = RFECV(estimator = model, step = 1, cv = 5, scoring = 'r2')\n",
    "rfecv = rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"The optimal number of features:\", rfecv.n_features_)\n",
    "print(\"Best features:\", X_train.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee47c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result: 0.7256591763365267\n",
      "Test Result: 0.7266961484398649\n"
     ]
    }
   ],
   "source": [
    "X_train_selected = rfecv.transform(X_train)\n",
    "X_test_selected = rfecv.transform(X_test)\n",
    "\n",
    "model = XGBRFRegressor(random_state = 1234)\n",
    "model.fit(X_train_selected, y_train)\n",
    "y_pred_train = model.predict(X_train_selected)\n",
    "result_train = 1 - np.sqrt(np.square(np.log10(y_pred_train +1) - np.log10(y_train +1)).mean())\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "result_test = 1 - np.sqrt(np.square(np.log10(y_pred_test +1) - np.log10(y_test +1)).mean())\n",
    "print(\"Train Result:\", result_train)\n",
    "print(\"Test Result:\", result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02ea9f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-20 16:05:56,672] A new study created in memory with name: no-name-7784f8ff-a00f-453b-a726-b4eaa42706f6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fd6e12ac9f4f66874182c9a25af160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-20 16:05:57,409] Trial 0 finished with value: -0.02691558977087305 and parameters: {'n_estimators': 223, 'max_depth': 7, 'learning_rate': 0.08225016588110448, 'subsample': 0.6566240518508436, 'colsample_bytree': 0.8421330375094473, 'reg_alpha': 0.9791637022628278, 'reg_lambda': 0.8181412397082952}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:05:58,970] Trial 1 finished with value: -0.13507724045917535 and parameters: {'n_estimators': 476, 'max_depth': 8, 'learning_rate': 0.06266092649114956, 'subsample': 0.552698767421453, 'colsample_bytree': 0.9129394771480208, 'reg_alpha': 0.48281094353963727, 'reg_lambda': 0.22941959679234036}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:00,439] Trial 2 finished with value: -0.8874083385848384 and parameters: {'n_estimators': 794, 'max_depth': 5, 'learning_rate': 0.0064614754232904725, 'subsample': 0.8106757209436106, 'colsample_bytree': 0.8999733096458864, 'reg_alpha': 0.6747171994340752, 'reg_lambda': 0.20950846964156777}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:02,140] Trial 3 finished with value: -0.10066330988501493 and parameters: {'n_estimators': 460, 'max_depth': 10, 'learning_rate': 0.06921780863351404, 'subsample': 0.7800498399819207, 'colsample_bytree': 0.9315190500723205, 'reg_alpha': 0.6429944865588331, 'reg_lambda': 0.900136452284527}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:03,586] Trial 4 finished with value: -0.1493433122575052 and parameters: {'n_estimators': 294, 'max_depth': 15, 'learning_rate': 0.06021046889184193, 'subsample': 0.5369708043154879, 'colsample_bytree': 0.6080227210181919, 'reg_alpha': 0.41350448071953094, 'reg_lambda': 0.14193723476822662}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:03,984] Trial 5 finished with value: -0.3724802727648795 and parameters: {'n_estimators': 201, 'max_depth': 5, 'learning_rate': 0.033108340188884956, 'subsample': 0.6575652109008692, 'colsample_bytree': 0.6448099850304825, 'reg_alpha': 0.19333427057204866, 'reg_lambda': 0.7859697244825725}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:04,627] Trial 6 finished with value: -0.1370091973225782 and parameters: {'n_estimators': 512, 'max_depth': 3, 'learning_rate': 0.06114801687166829, 'subsample': 0.8959937522570982, 'colsample_bytree': 0.8736038027016271, 'reg_alpha': 0.697560084859712, 'reg_lambda': 0.27842420664913936}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:05,581] Trial 7 finished with value: -1.1553871077902844 and parameters: {'n_estimators': 457, 'max_depth': 6, 'learning_rate': 0.0011865804801019435, 'subsample': 0.6234717992567971, 'colsample_bytree': 0.563981216006282, 'reg_alpha': 0.9212958207019157, 'reg_lambda': 0.17527191356867988}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:06,266] Trial 8 finished with value: -0.5187988416443121 and parameters: {'n_estimators': 136, 'max_depth': 15, 'learning_rate': 0.022620370121388757, 'subsample': 0.6813319141451839, 'colsample_bytree': 0.8407161818044847, 'reg_alpha': 0.5672831787932435, 'reg_lambda': 0.8387726121702244}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:07,561] Trial 9 finished with value: -0.03811248860878491 and parameters: {'n_estimators': 674, 'max_depth': 5, 'learning_rate': 0.07932217454170012, 'subsample': 0.7706068156840671, 'colsample_bytree': 0.9022227972903873, 'reg_alpha': 0.45057066449505667, 'reg_lambda': 0.4269546301868151}. Best is trial 0 with value: -0.02691558977087305.\n",
      "[I 2023-06-20 16:06:11,386] Trial 10 finished with value: 0.042528166906596665 and parameters: {'n_estimators': 971, 'max_depth': 11, 'learning_rate': 0.0988588288573315, 'subsample': 0.9767041809523762, 'colsample_bytree': 0.7547981757147433, 'reg_alpha': 0.9724592359979631, 'reg_lambda': 0.6671992860044349}. Best is trial 10 with value: 0.042528166906596665.\n",
      "[I 2023-06-20 16:06:15,041] Trial 11 finished with value: 0.04456684654394938 and parameters: {'n_estimators': 958, 'max_depth': 11, 'learning_rate': 0.09936938593546361, 'subsample': 0.9938897966609194, 'colsample_bytree': 0.7634177625593079, 'reg_alpha': 0.9637705375959024, 'reg_lambda': 0.6541160102917407}. Best is trial 11 with value: 0.04456684654394938.\n",
      "[I 2023-06-20 16:06:18,311] Trial 12 finished with value: 0.038228973146456235 and parameters: {'n_estimators': 920, 'max_depth': 11, 'learning_rate': 0.09731927681716637, 'subsample': 0.9717320008654866, 'colsample_bytree': 0.7376901398299643, 'reg_alpha': 0.8579030045008081, 'reg_lambda': 0.6323068702023651}. Best is trial 11 with value: 0.04456684654394938.\n",
      "[I 2023-06-20 16:06:21,851] Trial 13 finished with value: 0.04664619168588646 and parameters: {'n_estimators': 935, 'max_depth': 12, 'learning_rate': 0.09954472535080429, 'subsample': 0.9965494376889608, 'colsample_bytree': 0.747276201447008, 'reg_alpha': 0.8173006341543604, 'reg_lambda': 0.5903885393788769}. Best is trial 13 with value: 0.04664619168588646.\n",
      "[I 2023-06-20 16:06:25,969] Trial 14 finished with value: 0.03942883535463981 and parameters: {'n_estimators': 832, 'max_depth': 13, 'learning_rate': 0.09988050054832842, 'subsample': 0.9147017354041276, 'colsample_bytree': 0.9877697665463703, 'reg_alpha': 0.800916045162475, 'reg_lambda': 0.9915953039568814}. Best is trial 13 with value: 0.04664619168588646.\n",
      "[I 2023-06-20 16:06:28,902] Trial 15 finished with value: -0.02673319967177834 and parameters: {'n_estimators': 685, 'max_depth': 13, 'learning_rate': 0.08284469943605287, 'subsample': 0.993117281127753, 'colsample_bytree': 0.7441481525227985, 'reg_alpha': 0.801030040025928, 'reg_lambda': 0.5196588300492226}. Best is trial 13 with value: 0.04664619168588646.\n",
      "[I 2023-06-20 16:06:35,779] Trial 16 finished with value: 0.0050134643276363855 and parameters: {'n_estimators': 991, 'max_depth': 13, 'learning_rate': 0.08839780463296375, 'subsample': 0.8697785419859493, 'colsample_bytree': 0.6872965732124404, 'reg_alpha': 0.8560465877825618, 'reg_lambda': 0.0027232581704282888}. Best is trial 13 with value: 0.04664619168588646.\n",
      "[I 2023-06-20 16:06:38,156] Trial 17 finished with value: -0.06836190804356601 and parameters: {'n_estimators': 840, 'max_depth': 9, 'learning_rate': 0.07332714660635813, 'subsample': 0.9321688054170414, 'colsample_bytree': 0.5228307833441456, 'reg_alpha': 0.9828529582623221, 'reg_lambda': 0.6671440625245542}. Best is trial 13 with value: 0.04664619168588646.\n",
      "[I 2023-06-20 16:06:42,335] Trial 18 finished with value: -0.238702040881293 and parameters: {'n_estimators': 663, 'max_depth': 12, 'learning_rate': 0.04839894126594619, 'subsample': 0.8530824233716179, 'colsample_bytree': 0.7958002954922229, 'reg_alpha': 0.746618300182195, 'reg_lambda': 0.4760897725797519}. Best is trial 13 with value: 0.04664619168588646.\n",
      "[I 2023-06-20 16:06:45,118] Trial 19 finished with value: 0.012995268355949663 and parameters: {'n_estimators': 762, 'max_depth': 9, 'learning_rate': 0.09074808927542512, 'subsample': 0.9979858858807694, 'colsample_bytree': 0.6811299455987891, 'reg_alpha': 0.8763404253331996, 'reg_lambda': 0.5433880674190396}. Best is trial 13 with value: 0.04664619168588646.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# def custom_metric(y_true, y_pred):\n",
    "#     return 1 - np.sqrt(np.square(np.log10(y_pred_test +1) - np.log10(y_test +1)).mean())\n",
    "\n",
    "def objective(trial):\n",
    "    param_space = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0)\n",
    "        #'objective': 'reg:msle',\n",
    "        #'eval_metric': custom_metric\n",
    "    }\n",
    "    \n",
    "    model = XGBRFRegressor(random_state = 1234, **param_space)\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred_test = model.predict(X_test_selected)\n",
    "    result_test = 1 - np.sqrt(np.square(np.log10(y_pred_test +1) - np.log10(y_test +1)).mean())\n",
    "    return result_test\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 20, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1410c816",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1124\\2644086113.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBRFRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1234\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresult_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_train\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_selected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trial' is not defined"
     ]
    }
   ],
   "source": [
    "model = XGBRFRegressor(random_state = 1234, **trial.params)\n",
    "model.fit(X_train_selected, y_train)\n",
    "y_pred_train = model.predict(X_train_selected)\n",
    "result_train = 1 - np.sqrt(np.square(np.log10(y_pred_train +1) - np.log10(y_train +1)).mean())\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "result_test = 1 - np.sqrt(np.square(np.log10(y_pred_test +1) - np.log10(y_test +1)).mean())\n",
    "print(\"Train Result:\", result_train)\n",
    "print(\"Test Result:\", result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118f498",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433de60",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4611f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"test.xlsx\")\n",
    "test[\"Experience\"] = test.Experience.apply(lambda x : ''.join(x.split(' ')[:1]))\n",
    "test['Experience'] = pd.to_numeric(test['Experience'])\n",
    "test[\"Rating\"] = test.Rating.apply(lambda x: ''.join(str(x).split('%')[:1]) if pd.notnull(x) else x)\n",
    "test['Rating'] = pd.to_numeric(test['Rating'], errors = 'coerce')\n",
    "test['Rating'] = test['Rating'].fillna(0)\n",
    "test['Rating'] = test['Rating'].astype('int64')\n",
    "test['Place'].fillna('missing', inplace = True)\n",
    "test[\"Area\"] = test.Place.apply(lambda x: ''.join(str(x).split(',')[:1]) if pd.notnull(x) else x)\n",
    "test[\"City\"] = test.Place.apply(lambda x: ''.join(str(x).split(',')[1:]) if pd.notnull(x) else x)\n",
    "test[\"City\"] = test.City.apply(lambda x: ''.join(str(x).split(' ')[1:]) if pd.notnull(x) else x)\n",
    "test['Miscellaneous_Info'].fillna('missing', inplace = True)\n",
    "test[\"Feedbacks\"] = test.Miscellaneous_Info.apply(lambda x: ''.join(str(x).split('%')[1:]) if pd.notnull(x) else x)\n",
    "test[\"Feedbacks\"] = test.Feedbacks.apply(lambda x: ''.join(str(x).split('F')[:1]) if pd.notnull(x) else x)\n",
    "test[\"Feedbacks\"] = test.Feedbacks.apply(lambda x: ''.join(str(x).split(' ')[1:]) if pd.notnull(x) else x)\n",
    "test.loc[test['Feedbacks'] == '', 'Feedbacks'] = '0'\n",
    "test['Feedbacks'] = pd.to_numeric(test['Feedbacks'], errors = 'coerce')\n",
    "test['Feedbacks'].fillna(0, inplace = True)\n",
    "test['Feedbacks'] = test['Feedbacks'].astype('int64')\n",
    "test[\"Misc_Fees\"] = test.Miscellaneous_Info.apply(lambda x: ''.join(str(x).split('₹')[1:]) if pd.notnull(x) else x)\n",
    "test['Misc_Fees'] = test['Misc_Fees'].str.replace(',', '')\n",
    "test[\"Misc_Fees\"] = test.Misc_Fees.apply(lambda x: ''.join(str(x).split(' ')[:1]) if pd.notnull(x) else x)\n",
    "test.loc[test['Misc_Fees'] == '', 'Misc_Fees'] = '0'\n",
    "test['Misc_Fees'] = pd.to_numeric(test['Misc_Fees'], errors = 'coerce')\n",
    "test['Misc_Fees'].fillna(0, inplace = True)\n",
    "test['Misc_Fees'] = test['Misc_Fees'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00ed61",
   "metadata": {},
   "source": [
    "## WINSORIZING OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e830ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# plt.rcParams['figure.figsize'] = (15,7)\n",
    "# f,(ax1, ax2) = plt.subplots(1,2)\n",
    "# sns.boxplot(y = 'Experience', data = test, ax = ax1, palette = 'coolwarm')\n",
    "# sns.boxplot(y = 'Rating', data = test, ax = ax2)\n",
    "# f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5eb3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in ['Experience', 'Rating']:\n",
    "#     IQR = test[column].quantile(0.75) - test[column].quantile(0.25)\n",
    "#     Lower_fence = test[column].quantile(0.25) - (IQR * 1.5)\n",
    "#     Upper_fence = test[column].quantile(0.75) + (IQR * 1.5)\n",
    "#     print(f'{column} outliers are values < {round(Lower_fence,2)} or > {round(Upper_fence,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b6af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['Experience'] = np.where(test['Experience'] > 46.5, 46.5, test['Experience'])\n",
    "# test['Rating'] = np.where(test['Rating'] < 91.0, 91.0, test['Rating'])\n",
    "# test['Rating'] = np.where(test['Rating'] > 99.0, 99.0, test['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc39ee",
   "metadata": {},
   "source": [
    "## DUMMIFICATION, MIN-MAX SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3bf67c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.get_dummies(test[['Profile', 'City']], drop_first = True)\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# scaled2 = scaler.fit_transform(test[['Experience', 'Rating']])\n",
    "# scaled_df2 = pd.DataFrame(scaled2, columns = ['Experience', 'Rating'])\n",
    "\n",
    "X2 = pd.concat([test[['Experience', 'Rating', 'Misc_Fees', 'Feedbacks']], X2], axis = 1)\n",
    "\n",
    "X2['City_Sector5Delhi'] = 0\n",
    "column = X2.pop('City_Sector5Delhi')\n",
    "X2.insert(16, 'City_Sector5Delhi', column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60027167",
   "metadata": {},
   "source": [
    "## WRITE INTO SUBMISSION FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fce8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 = rfecv.transform(X2)\n",
    "test['Fees'] = model.predict(X2)\n",
    "test['Fees'].to_excel('submission.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB WITH OPTUNA - 0.71910\n",
    "# XGB RANDOM FOREST REGRESSOR - 0.71483\n",
    "# LINEAR REGRESSION - 0.71378\n",
    "# XGB RANDOM FOREST REGRESSOR WITH FEATURE IMPORTANCE - 0.71284\n",
    "# DECISION TREE REGRESSOR - 0.71226"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a35b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
